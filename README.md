# Layer-wise_Fine-tuning_Based_Pre-trained-Language-Model-Knowledge
✏ KIICE2023 논문 repo

#### 이 논문은 [KLUE-baseline](https://github.com/KLUE-benchmark/KLUE-baseline) 을 기반하여 실험했습니다.

```bash
├── sts_data
│   ├── data_augmentation.py
│   ├── data_preprocessing.py
│   ├── generate_queries.py
│   ├── krx_api.py
│   ├── krx_db_utils.py
│   ├── krx_def.py
│   ├── masking_utils.py
│   └── squad_utils.py
└── Masking-klue-Roberta
    ├── main.py
    ├── multimasking
    │   └── multimasking.py
    ├── singlemaskingforwordtoken
    └── └── singlemasking.py
``` 

# Abstract
