# Layer-wise_Fine-tuning_Based_Pre-trained-Language-Model-Knowledge
✏ KIICE2023 논문 repo

#### 이 논문은 [KLUE-baseline](https://github.com/KLUE-benchmark/KLUE-baseline) 을 기반하여 실험했습니다.

## File Direcotry
```bash
├── data/klue_benchmark
│   ├── data_augmentation.py
│   ├── data_preprocessing.py
│   ├── generate_queries.py
│   ├── krx_api.py
│   ├── krx_db_utils.py
│   ├── krx_def.py
│   ├── masking_utils.py
│   └── squad_utils.py
├── klue-baseline
│   ├── data_augmentation.py
│   ├── data_preprocessing.py
│   ├── generate_queries.py
│   ├── krx_api.py
│   ├── krx_db_utils.py
│   ├── krx_def.py
│   ├── masking_utils.py
│   └── squad_utils.py
└── 
    ├── main.py
    ├── multimasking
    │   └── multimasking.py
    ├── singlemaskingforwordtoken
    └── └── singlemasking.py
``` 

# Abstract


---
# Version
'''
pip install -r requirements.txt
'''
